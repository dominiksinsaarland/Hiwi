('H01-1001', ['information_retrieval_techniques', 'use', 'a', 'histogram', 'of', 'keywords'], 'H01-1001.5', 'H01-1001.7', 'USAGE REVERSE', 6)
('H01-1001', ['oral_communication', 'may', 'offer', 'additional', 'indices'], 'H01-1001.9', 'H01-1001.10', 'USAGE', 5)
('H01-1001', ['database', 'of', 'TV_shows'], 'H01-1001.14', 'H01-1001.15', 'PART_WHOLE REVERSE', 3)
('H01-1017', ['distributed_message-passing_infrastructure', 'for', 'dialogue_systems'], 'H01-1017.4', 'H01-1017.5', 'MODEL-FEATURE', 3)
('H01-1041', ['CCLINC_Korean-to-English_translation_system', 'consists', 'of', 'two', 'core_modules'], 'H01-1041.3', 'H01-1041.4', 'PART_WHOLE REVERSE', 5)
('H01-1041', ['parsing', 'of', 'Korean'], 'H01-1041.8', 'H01-1041.9', 'USAGE', 3)
('H01-1041', ['verb_final_language', 'with', 'overt_case_markers'], 'H01-1041.10', 'H01-1041.11', 'MODEL-FEATURE REVERSE', 3)
('H01-1041', ['translation', 'via', 'word_sense_disambiguation'], 'H01-1041.14', 'H01-1041.15', 'USAGE REVERSE', 3)
('H01-1042', ['automated_evaluation_techniques,', 'originally', 'devised', 'for', 'the', 'evaluation', 'of', 'human language learners,', 'to', 'the', 'output'], 'H01-1042.1', 'H01-1042.3', 'USAGE', 11)
('H01-1042', ['intelligibility', 'of', 'MT_output'], 'H01-1042.10', 'H01-1042.11', 'MODEL-FEATURE', 3)
('H01-1049', ['spoken_language_understanding_system', 'with', 'intelligent_mobile_agents'], 'H01-1049.3', 'H01-1049.4', 'PART_WHOLE REVERSE', 3)
('H01-1058', ['interpolation_methods,', 'like', 'log-linear and linear interpolation,', 'improve', 'the', 'performance'], 'H01-1058.2', 'H01-1058.4', 'RESULT', 6)
('H01-1058', ['word_string', 'with', 'the', 'best', 'performance'], 'H01-1058.9', 'H01-1058.10', 'RESULT', 5)
('H01-1058', ['word_string', 'has', 'been', 'obtained', 'by', 'using', 'a', 'different', 'LM'], 'H01-1058.13', 'H01-1058.14', 'RESULT REVERSE', 9)
('H01-1058', ['dynamic_combiner', 'with', 'hard decisions', 'using', 'the', 'reference'], 'H01-1058.16', 'H01-1058.18', 'USAGE REVERSE', 6)
('H01-1058', ['dynamic_language_model_combination', 'to', 'improve', 'the', 'performance'], 'H01-1058.19', 'H01-1058.20', 'RESULT', 5)
('H01-1058', ['LMs', 'with', 'confidence_measures'], 'H01-1058.24', 'H01-1058.25', 'MODEL-FEATURE REVERSE', 3)
('H01-1058', ['LM', 'with', 'the', 'best', 'confidence'], 'H01-1058.27', 'H01-1058.28', 'MODEL-FEATURE REVERSE', 5)
('H01-1070', ['error-correction_rules', 'for', 'Thai_key_prediction'], 'H01-1070.2', 'H01-1070.3', 'USAGE', 3)
('H01-1070', ['mutual_information', 'to', 'reduce', 'the', 'error-correction_rules'], 'H01-1070.6', 'H01-1070.7', 'USAGE', 5)
('H01-1070', ['accuracy', 'in', 'both', 'language_identification'], 'H01-1070.8', 'H01-1070.9', 'RESULT REVERSE', 4)
('N01-1003', ['sentence_plans', 'for', 'a', 'given', 'text-plan_input'], 'N01-1003.12', 'N01-1003.13', 'MODEL-FEATURE', 5)
('N01-1003', ['ranking_rules', 'automatically', 'learned', 'from', 'training_data'], 'N01-1003.18', 'N01-1003.19', 'USAGE REVERSE', 5)
('N01-1003', ['sentence_plan', 'whose', 'rating', 'on', 'average', 'is', 'only', '5%', 'worse', 'than', 'the', 'top_human-ranked_sentence_plan'], 'N01-1003.21', 'N01-1003.22', 'COMPARE', 12)
('P01-1004', ['retrieval_performance', 'of', 'a', 'translation_memory_system'], 'P01-1004.4', 'P01-1004.5', 'RESULT REVERSE', 4)
('P01-1004', ['bag-of-words_and_segment_order-sensitive_string_comparison_methods,', 'and', 'run', 'each', 'over', 'both', 'character-_and_word-segmented_data'], 'P01-1004.6', 'P01-1004.7', 'USAGE', 7)
('P01-1004', ['indexing', 'according', 'to', 'simple', 'character_bigrams'], 'P01-1004.11', 'P01-1004.12', 'USAGE REVERSE', 5)
('P01-1004', ['bag-of-words_methods', 'are', 'shown', 'to', 'be', 'equivalent', 'to', 'segment_order-sensitive_methods'], 'P01-1004.16', 'P01-1004.17', 'COMPARE', 8)
('P01-1007', ['range_concatenation_grammar_[RCG]_formalism', 'has', 'revealed', 'many', 'attractive', 'properties', 'which', 'may', 'be', 'used', 'in', 'NLP'], 'P01-1007.1', 'P01-1007.2', 'USAGE', 12)
('P01-1007', ['range_concatenation_languages_[RCL]', 'can', 'be', 'parsed', 'in', 'polynomial_time'], 'P01-1007.3', 'P01-1007.4', 'MODEL-FEATURE REVERSE', 6)
('P01-1007', ['tree_adjoining_grammar', 'can', 'be', 'parsed', 'in', 'O(n6)_time'], 'P01-1007.10', 'P01-1007.11', 'MODEL-FEATURE REVERSE', 6)
('P01-1007', ['parsing_technique', 'whose', 'purpose', 'is', 'to', 'improve', 'the', 'practical', 'efficiency', 'of', 'RCL_parsers'], 'P01-1007.12', 'P01-1007.13', 'USAGE', 11)
('P01-1007', ['guide', 'which', 'uses', 'the', 'shared_derivation_forest'], 'P01-1007.17', 'P01-1007.18', 'USAGE REVERSE', 5)
('P01-1007', ['RCL_parser', 'for', 'a', 'suitable', 'superset_of_L'], 'P01-1007.19', 'P01-1007.20', 'USAGE', 5)
('P01-1008', ['paraphrasing', 'is', 'critical', 'both', 'for', 'interpretation_and_generation_of_natural_language'], 'P01-1008.1', 'P01-1008.2', 'USAGE', 6)
('P01-1008', ['unsupervised_learning_algorithm', 'for', 'identification_of_paraphrases'], 'P01-1008.4', 'P01-1008.5', 'USAGE', 3)
('P01-1009', ['formal_analysis', 'for', 'a', 'large', 'class', 'of', 'words', 'called', 'alternative_markers'], 'P01-1009.1', 'P01-1009.3', 'TOPIC', 9)
('P01-1009', ['performance', 'of', 'a', 'search engine', 'can', 'be', 'improved', 'dramatically', 'by', 'incorporating', 'an', 'approximation', 'of', 'the', 'formal_analysis'], 'P01-1009.12', 'P01-1009.14', 'RESULT REVERSE', 15)
('P01-1009', ['operational_semantics', 'of', 'natural_language_applications'], 'P01-1009.17', 'P01-1009.18', 'PART_WHOLE', 3)
('P01-1047', ['learning_algorithm', 'from', 'structured_data'], 'P01-1047.10', 'P01-1047.11', 'USAGE REVERSE', 3)
('P01-1056', ['quality', 'of', 'utterances'], 'P01-1056.3', 'P01-1056.4', 'MODEL-FEATURE', 3)
('P01-1056', ['trainable_components', 'can', 'compete', 'with', 'hand-crafted_template-based_or_rule-based_approaches'], 'P01-1056.5', 'P01-1056.6', 'COMPARE', 5)
('P01-1056', ['trainable_sentence_planner', 'for', 'a', 'spoken_dialogue_system'], 'P01-1056.7', 'P01-1056.8', 'USAGE', 4)
('P01-1056', ['trainable_sentence_planner', 'performs', 'better', 'than', 'the', 'rule-based_systems'], 'P01-1056.13', 'P01-1056.14', 'COMPARE', 6)
('P01-1070', ['statistical_models', 'of', 'WH-questions'], 'P01-1070.2', 'P01-1070.3', 'MODEL-FEATURE', 3)
('P01-1070', ['shallow_linguistic_features', 'of', 'questions'], 'P01-1070.5', 'P01-1070.6', 'MODEL-FEATURE', 3)
('P01-1070', ['predictive_performance', 'of', 'our', 'models'], 'P01-1070.8', 'P01-1070.9', 'RESULT REVERSE', 4)
('P01-1070', ['training_and_testing_factors', 'on', 'predictive_performance'], 'P01-1070.10', 'P01-1070.11', 'RESULT', 3)
('N03-1001', ['utterance_classification', 'that', 'does', 'not', 'require', 'manual_transcription'], 'N03-1001.1', 'N03-1001.2', 'USAGE REVERSE', 6)
('N03-1001', ['word-trigram_recognition', 'requiring', 'manual_transcription'], 'N03-1001.7', 'N03-1001.8', 'USAGE REVERSE', 3)
('N03-1001', ['unsupervised_training', 'is', 'first', 'used', 'to', 'train', 'a', 'phone_n-gram_model'], 'N03-1001.9', 'N03-1001.10', 'USAGE', 8)
('N03-1001', ['output', 'of', 'recognition', 'with', 'this', 'model', 'is', 'then', 'passed', 'to', 'a', 'phone-string_classifier'], 'N03-1001.12', 'N03-1001.15', 'USAGE REVERSE', 12)
('N03-1004', ['multi-strategy_and_multi-source_approach_to_question_answering', 'which', 'is', 'based', 'on', 'combining', 'the', 'results', 'from', 'different', 'answering_agents'], 'N03-1004.4', 'N03-1004.5', 'USAGE REVERSE', 11)
('N03-1004', ['answers', 'in', 'multiple', 'corpora'], 'N03-1004.6', 'N03-1004.7', 'PART_WHOLE', 4)
('N03-1004', ['answering_agents', 'adopt', 'fundamentally', 'different', 'strategies,', 'one', 'utilizing', 'primarily', 'knowledge-based_mechanisms'], 'N03-1004.8', 'N03-1004.9', 'USAGE REVERSE', 9)
('N03-1004', ['answer_resolution_algorithm', 'show', 'a', '35.0%', 'relative', 'improvement', 'over', 'our', 'baseline_system'], 'N03-1004.14', 'N03-1004.15', 'COMPARE', 9)
('N03-1012', ['scoring', 'alternative', 'speech_recognition_hypotheses_(SRH)'], 'N03-1012.4', 'N03-1012.5', 'USAGE', 3)
('N03-1012', ['German_corpus', 'of', '2.284', 'SRHs'], 'N03-1012.11', 'N03-1012.12', 'PART_WHOLE REVERSE', 4)
('N03-1017', ['phrase-based_models', 'outperform', 'word-based_models'], 'N03-1017.4', 'N03-1017.5', 'COMPARE', 3)
('N03-1017', ['heuristic_learning', 'of', 'phrase translations', 'from', 'word-based_alignments'], 'N03-1017.7', 'N03-1017.9', 'USAGE REVERSE', 5)
('N03-1017', ['lexical_weighting', 'of', 'phrase_translations'], 'N03-1017.10', 'N03-1017.11', 'MODEL-FEATURE', 3)
('N03-1017', ['phrases', 'from', 'high-accuracy_word-level_alignment_models'], 'N03-1017.14', 'N03-1017.15', 'PART_WHOLE', 3)
('N03-1018', ['model', 'is', 'designed', 'for', 'use', 'in', 'error_correction'], 'N03-1018.6', 'N03-1018.7', 'USAGE', 7)
('N03-1018', ['post-processing', 'the', 'output'], 'N03-1018.8', 'N03-1018.9', 'USAGE', 3)
('N03-1018', ['model', 'based', 'on', 'finite-state_models'], 'N03-1018.12', 'N03-1018.13', 'USAGE REVERSE', 4)
('N03-1018', ['model', "'s", 'ability', 'to', 'significantly', 'reduce', 'character_and_word_error_rate'], 'N03-1018.14', 'N03-1018.15', 'RESULT', 7)
('N03-1018', ['automatic_extraction', 'of', 'translation lexicons', 'from', 'printed_text'], 'N03-1018.16', 'N03-1018.18', 'USAGE', 5)
('N03-1026', ['ambiguity_packing_and_stochastic_disambiguation_techniques', 'for', 'Lexical-Functional_Grammars_(LFG)'], 'N03-1026.1', 'N03-1026.2', 'USAGE', 3)
('N03-1026', ['linguistic_parser/generator', 'for', 'LFG'], 'N03-1026.4', 'N03-1026.5', 'USAGE', 3)
('N03-1026', ['transfer_component', 'for', 'parse_reduction'], 'N03-1026.6', 'N03-1026.7', 'USAGE', 3)
('N03-1026', ['maximum-entropy_model', 'for', 'stochastic_output_selection'], 'N03-1026.9', 'N03-1026.10', 'USAGE REVERSE', 3)
('N03-1026', ['experimental_evaluation', 'of', 'summarization'], 'N03-1026.14', 'N03-1026.15', 'TOPIC', 3)
('N03-1026', ['grammaticality', 'of', 'the', 'system_output'], 'N03-1026.20', 'N03-1026.21', 'MODEL-FEATURE', 4)
('N03-1033', ['priors', 'in', 'conditional_loglinear_models'], 'N03-1033.6', 'N03-1033.7', 'USAGE', 3)
('N03-1033', ['tagger', 'gives', 'a', '97.24%', 'accuracy'], 'N03-1033.9', 'N03-1033.10', 'RESULT', 5)
('N03-2003', ['training_data', 'suitable', 'for', 'language_modeling'], 'N03-2003.1', 'N03-2003.2', 'USAGE', 4)
('N03-2003', ['text', 'from', 'the', 'web'], 'N03-2003.5', 'N03-2003.6', 'PART_WHOLE', 4)
('N03-2006', ['translation_quality', 'of', 'EBMT'], 'N03-2006.1', 'N03-2006.2', 'RESULT REVERSE', 3)
('N03-2015', ['hubs', 'in', 'an', 'automaton'], 'N03-2015.3', 'N03-2015.4', 'PART_WHOLE', 4)
('N03-2017', ['syntax-based_constraint', 'for', 'word_alignment'], 'N03-2017.1', 'N03-2017.2', 'USAGE', 3)
('N03-2025', ['bootstrapping_approach', 'to', 'Named_Entity_(NE)_tagging'], 'N03-2025.1', 'N03-2025.2', 'USAGE', 3)
('N03-2025', ['seeds', 'that', 'correspond', 'to', 'the', 'concept'], 'N03-2025.7', 'N03-2025.8', 'MODEL-FEATURE', 6)
('N03-2025', ['decision_list', 'is', 'used', 'to', 'learn', 'the', 'parsing-based_NE_rules'], 'N03-2025.13', 'N03-2025.14', 'USAGE REVERSE', 7)
('N03-2025', ['Hidden_Markov_Model', 'is', 'trained', 'on', 'a', 'corpus'], 'N03-2025.15', 'N03-2025.16', 'USAGE', 6)
('N03-2036', ['phrase-based_unigram_model', 'for', 'statistical_machine_translation'], 'N03-2036.1', 'N03-2036.2', 'USAGE', 3)
('N03-2036', ['blocks', 'are', 'learned', 'from', 'source_interval_projections'], 'N03-2036.12', 'N03-2036.13', 'PART_WHOLE', 5)
('N03-2036', ['block_selection_criteria', 'based', 'on', 'unigram'], 'N03-2036.15', 'N03-2036.16', 'USAGE REVERSE', 4)
('N03-3010', ['Cooperative_Model', 'for', 'natural_language_understanding'], 'N03-3010.1', 'N03-3010.2', 'USAGE', 3)
('N03-4010', ['JAVELIN_system', 'integrates', 'a', 'flexible,', 'planning-based_architecture'], 'N03-4010.1', 'N03-4010.2', 'PART_WHOLE REVERSE', 5)
('N03-4010', ['JAVELIN', 'processes', 'questions'], 'N03-4010.6', 'N03-4010.7', 'USAGE', 3)
('N03-4010', ['answer_candidates', 'from', 'the', 'given', 'text_corpus'], 'N03-4010.8', 'N03-4010.9', 'PART_WHOLE', 5)
('N03-4010', ['repository', 'of', 'data_objects'], 'N03-4010.10', 'N03-4010.11', 'PART_WHOLE REVERSE', 3)
('P03-1002', ['IE_paradigm', 'that', 'takes', 'advantage', 'of', 'predicate-argument_structures'], 'P03-1002.1', 'P03-1002.2', 'USAGE REVERSE', 6)
('P03-1005', ['Hierarchical_Directed_Acyclic_Graph_(HDAG)_Kernel', 'for', 'structured_natural_language_data'], 'P03-1005.1', 'P03-1005.2', 'USAGE', 3)
('P03-1005', ['attribute_sequences', 'of', 'the', 'HDAGs'], 'P03-1005.7', 'P03-1005.8', 'MODEL-FEATURE', 4)
('P03-1005', ['HDAG_Kernel', 'is', 'superior', 'to', 'other', 'kernel_functions'], 'P03-1005.13', 'P03-1005.14', 'COMPARE', 6)
('P03-1009', ['semantic_verb_classes', 'from', 'undisambiguated', 'corpus_data'], 'P03-1009.2', 'P03-1009.3', 'MODEL-FEATURE', 4)
('P03-1009', ['subcategorization_frame_(SCF)', 'distributions', 'using', 'the', 'Information_Bottleneck'], 'P03-1009.4', 'P03-1009.5', 'USAGE REVERSE', 5)
('P03-1009', ['polysemy', 'on', 'the', 'clusters'], 'P03-1009.9', 'P03-1009.10', 'MODEL-FEATURE', 4)
('P03-1022', ['decision_tree_based_approach', 'to', 'pronoun_resolution'], 'P03-1022.1', 'P03-1022.2', 'USAGE', 3)
('P03-1022', ['pronouns', 'with', 'NP-_and_non-NP-antecedents'], 'P03-1022.4', 'P03-1022.5', 'MODEL-FEATURE REVERSE', 3)
('P03-1022', ['pronoun_resolution', 'in', 'spoken_dialogue'], 'P03-1022.7', 'P03-1022.8', 'USAGE', 3)
('P03-1030', ['Topic_Detection_and_Tracking_tasks', 'of', 'new_event_detection'], 'P03-1030.2', 'P03-1030.3', 'PART_WHOLE', 3)
('P03-1031', ['discourse_understanding_process', 'in', 'spoken_dialogue_systems'], 'P03-1031.1', 'P03-1031.2', 'USAGE', 3)
('P03-1031', ['context', 'of', 'a', 'dialogue'], 'P03-1031.4', 'P03-1031.5', 'MODEL-FEATURE', 4)
('P03-1031', ['candidates', 'for', 'the', 'understanding'], 'P03-1031.6', 'P03-1031.7', 'USAGE', 4)
('P03-1031', ['ambiguity', 'of', 'speech_understanding'], 'P03-1031.9', 'P03-1031.10', 'MODEL-FEATURE', 3)
('P03-1031', ['candidates', 'for', 'understanding'], 'P03-1031.13', 'P03-1031.14', 'USAGE', 3)
('P03-1031', ['statistical_information', 'obtained', 'from', 'dialogue_corpora'], 'P03-1031.19', 'P03-1031.20', 'MODEL-FEATURE', 4)
('P03-1031', ['candidates', 'for', 'understanding'], 'P03-1031.23', 'P03-1031.24', 'USAGE', 3)
('P03-1033', ['user_modeling', 'in', 'order', 'to', 'generate', 'cooperative_responses'], 'P03-1033.1', 'P03-1033.2', 'USAGE', 6)
('P03-1033', ['models', 'are', 'automatically', 'derived', 'by', 'decision_tree_learning'], 'P03-1033.14', 'P03-1033.15', 'MODEL-FEATURE REVERSE', 6)
('P03-1033', ['Dialogue_strategies', 'based', 'on', 'the', 'user_modeling'], 'P03-1033.18', 'P03-1033.19', 'USAGE REVERSE', 5)
('P03-1050', ['unsupervised_learning_approach', 'to', 'building', 'a', 'non-English_(Arabic)_stemmer'], 'P03-1050.1', 'P03-1050.2', 'USAGE', 5)
('P03-1050', ['stemming_model', 'is', 'based', 'on', 'statistical_machine_translation'], 'P03-1050.3', 'P03-1050.4', 'USAGE REVERSE', 5)
('P03-1050', ['language', 'that', 'needs', 'affix_removal'], 'P03-1050.15', 'P03-1050.16', 'MODEL-FEATURE REVERSE', 4)
('P03-1050', ['resource-frugal_approach', 'results', 'in', '87.5%', 'agreement'], 'P03-1050.17', 'P03-1050.18', 'RESULT', 5)
('P03-1050', ['Task-based_evaluation', 'using', 'Arabic_information_retrieval'], 'P03-1050.24', 'P03-1050.25', 'USAGE REVERSE', 3)
('P03-1051', ['manually_segmented_Arabic_corpus', 'and', 'uses', 'it', 'to', 'bootstrap', 'an', 'unsupervised_algorithm'], 'P03-1051.8', 'P03-1051.9', 'USAGE', 8)
('P03-1051', ['Arabic_word_segmenter', 'from', 'a', 'large', 'unsegmented_Arabic_corpus'], 'P03-1051.10', 'P03-1051.11', 'USAGE REVERSE', 5)
('P03-1051', ['morpheme_sequence', 'for', 'a', 'given', 'input'], 'P03-1051.13', 'P03-1051.14', 'MODEL-FEATURE', 5)
('P03-1051', ['language_model', 'is', 'initially', 'estimated', 'from', 'a', 'small', 'manually_segmented_corpus'], 'P03-1051.15', 'P03-1051.16', 'MODEL-FEATURE', 8)
('P03-1051', ['stems', 'from', 'a', '155', 'million', 'word', 'unsegmented_corpus'], 'P03-1051.21', 'P03-1051.23', 'PART_WHOLE', 7)
('P03-1051', ['model_parameters', 'with', 'the', 'expanded', 'vocabulary'], 'P03-1051.24', 'P03-1051.25', 'USAGE', 5)
('P03-1051', ['Arabic_word_segmentation_system', 'achieves', 'around', '97%', 'exact_match_accuracy'], 'P03-1051.27', 'P03-1051.28', 'RESULT', 5)
('P03-1051', ['test_corpus', 'containing', '28,449', 'word_tokens'], 'P03-1051.29', 'P03-1051.30', 'PART_WHOLE REVERSE', 4)
('P03-1051', ['manually_segmented_corpus', 'of', 'the', 'language'], 'P03-1051.32', 'P03-1051.33', 'MODEL-FEATURE', 4)
('P03-1058', ['word_sense_disambiguation_(WSD)', 'is', 'the', 'lack', 'of', 'manually_sense-tagged_data'], 'P03-1058.1', 'P03-1058.2', 'USAGE REVERSE', 6)
('P03-1058', ['sense-tagged_training_data', 'from', 'English-Chinese_parallel_corpora'], 'P03-1058.4', 'P03-1058.5', 'MODEL-FEATURE', 3)
('P03-1058', ['domain_dependence', 'in', 'evaluating', 'WSD_programs'], 'P03-1058.13', 'P03-1058.14', 'MODEL-FEATURE', 4)
('P03-1068', ['semantically_annotated_corpus', 'resource', 'as', 'reliable', 'basis', 'for', 'the', 'large-scale', 'acquisition_of_word-semantic_information'], 'P03-1068.1', 'P03-1068.2', 'USAGE', 9)
('P03-1068', ['ambiguity', 'in', 'semantic_annotation'], 'P03-1068.9', 'P03-1068.10', 'MODEL-FEATURE', 3)
('P03-1070', ['attentional_focus', 'in', 'the', 'context', 'of', 'a', 'direction-giving_task'], 'P03-1070.9', 'P03-1070.10', 'MODEL-FEATURE', 7)
('P03-1070', ['ECA', 'that', 'uses', 'verbal_and_nonverbal_grounding_acts'], 'P03-1070.14', 'P03-1070.15', 'USAGE REVERSE', 4)
('P03-2036', ['HPSG', 'produces', 'a', 'more', 'effective', 'CFG filter', 'than', 'that', 'of', 'LTAG'], 'P03-2036.4', 'P03-2036.6', 'COMPARE', 10)
('C04-1106', ['analogies', 'among', 'the', 'sentences'], 'C04-1106.5', 'C04-1106.6', 'MODEL-FEATURE', 4)
('N04-1024', ['CriterionSM_Online_Essay_Evaluation_Service', 'includes', 'a', 'capability', 'that', 'labels', 'sentences', 'in', 'student', 'writing'], 'N04-1024.1', 'N04-1024.3', 'USAGE', 10)
('N04-1024', ['coherence', 'in', 'essays'], 'N04-1024.7', 'N04-1024.8', 'MODEL-FEATURE', 3)
('N04-1024', ['features', 'of', 'sentences'], 'N04-1024.9', 'N04-1024.10', 'MODEL-FEATURE', 3)
('N04-1024', ['support_vector_machine', 'uses', 'these', 'features'], 'N04-1024.13', 'N04-1024.14', 'USAGE REVERSE', 4)
('N04-1024', ['Intra-sentential_quality', 'is', 'evaluated', 'with', 'rule-based_heuristics'], 'N04-1024.18', 'N04-1024.19', 'TOPIC REVERSE', 5)
('H05-1005', ['information_redundancy', 'in', 'multilingual_input'], 'H05-1005.1', 'H05-1005.2', 'MODEL-FEATURE', 3)
('H05-1005', ['documents', 'are', 'in', 'Arabic'], 'H05-1005.6', 'H05-1005.7', 'MODEL-FEATURE REVERSE', 4)
('H05-1005', ['summary', 'is', 'in', 'English'], 'H05-1005.8', 'H05-1005.9', 'MODEL-FEATURE REVERSE', 4)
('H05-1005', ['information', 'in', 'English'], 'H05-1005.15', 'H05-1005.16', 'MODEL-FEATURE REVERSE', 3)
('H05-1012', ['maximum_entropy_word_alignment_algorithm', 'for', 'Arabic-English', 'based', 'on', 'supervised_training_data'], 'H05-1012.1', 'H05-1012.3', 'USAGE REVERSE', 6)
('H05-1012', ['supervised_and_unsupervised_methods', 'yields', 'superior', 'performance'], 'H05-1012.6', 'H05-1012.7', 'RESULT', 4)
('H05-1012', ['probabilistic_model', 'used', 'in', 'the', 'alignment'], 'H05-1012.8', 'H05-1012.9', 'USAGE', 5)
('H05-1095', ['phrase-based_statistical_machine_translation_method,', 'based', 'on', 'non-contiguous_phrases'], 'H05-1095.1', 'H05-1095.2', 'USAGE REVERSE', 4)
('H05-1095', ['phrases', 'from', 'a', 'word-aligned_corpora'], 'H05-1095.4', 'H05-1095.5', 'PART_WHOLE', 4)
('H05-1095', ['statistical_translation_model', 'is', 'also', 'presented', 'that', 'deals', 'such', 'phrases'], 'H05-1095.6', 'H05-1095.7', 'USAGE', 8)
('H05-1095', ['training_method', 'based', 'on', 'the', 'maximization', 'of', 'translation_accuracy'], 'H05-1095.8', 'H05-1095.9', 'USAGE REVERSE', 7)
('H05-1095', ['Translations', 'are', 'produced', 'by', 'means', 'of', 'a', 'beam-search_decoder'], 'H05-1095.11', 'H05-1095.12', 'USAGE REVERSE', 8)
('H05-1117', ['automatic_evaluation', 'of', 'machine_translation'], 'H05-1117.1', 'H05-1117.2', 'USAGE', 3)
('H05-1117', ['rankings', 'produced', 'by', 'our', 'metric', 'correlate', 'highly', 'with', 'official_rankings'], 'H05-1117.8', 'H05-1117.9', 'COMPARE', 9)
('H05-2007', ['patterns', 'in', 'translation_data'], 'H05-2007.1', 'H05-2007.2', 'PART_WHOLE', 3)
('H05-2007', ['patterns', 'in', 'machine_translation_output'], 'H05-2007.8', 'H05-2007.9', 'PART_WHOLE', 3)
